{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7be6bec9",
   "metadata": {},
   "source": [
    "# Preprocessing Pipeline: Resample and Crop\n",
    "\n",
    "This notebook orchestrates the full preprocessing pipeline for all subjects. It reads configuration from `configs/main_config.yaml`, imports functions from `src/preprocessing.py`, and processes each subject."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a3cd02",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "\n",
    "Load necessary libraries, configuration file, and custom preprocessing functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d273efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded successfully:\n",
      "dataset:\n",
      "  modalities:\n",
      "  - pet\n",
      "  - ct\n",
      "paths:\n",
      "  data_root: data/0_nifti\n",
      "  output_dir: results/\n",
      "  participants_tsv: metadata/participants.tsv\n",
      "preprocessing:\n",
      "  crop_method: lung_ROI\n",
      "  min_lung_size: 100\n",
      "  output_dir: data/1_preprocessed\n",
      "  target_spacing:\n",
      "  - 1.5\n",
      "  - 1.5\n",
      "  - 3.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "import SimpleITK as sitk\n",
    "\n",
    "# Add src directory to the Python path to import preprocessing functions\n",
    "project_root = Path.cwd().resolve().parents[1]\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "from src.preprocessing import calculate_resample_template, resample_image, remove_small_objects, get_bounding_box, crop_to_bounding_box\n",
    "\n",
    "# Load main configuration\n",
    "config_path = project_root / 'configs' / 'main_config.yaml'\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration loaded successfully:\")\n",
    "print(yaml.dump(config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012b97fe",
   "metadata": {},
   "source": [
    "## 2. Define Paths and Identify Subjects\n",
    "\n",
    "Use the loaded configuration to set up input and output directories and get a list of all subjects to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73aa1b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_subject(subject_id: str, source_dir: Path, output_dir: Path, config: dict):\n",
    "    \"\"\"\n",
    "    Main function to preprocess a single subject: resample and crop.\n",
    "\n",
    "    :param subject_id: The ID of the subject (e.g., 'sub-AKHABDALLAADELAHMED20091023').\n",
    "    :param source_dir: The root directory of the raw data.\n",
    "    :param output_dir: The root directory to save preprocessed data.\n",
    "    :param config: A dictionary containing preprocessing parameters.\n",
    "    \"\"\"\n",
    "    subject_source_dir = source_dir / subject_id\n",
    "    \n",
    "    # 1. Define and check all file paths\n",
    "    path_map = {\n",
    "        \"ct\": subject_source_dir / f\"{subject_id}_ct.nii.gz\",\n",
    "        \"pet\": subject_source_dir / f\"{subject_id}_pet.nii.gz\",\n",
    "        \"seg_lung\": subject_source_dir / f\"{subject_id}_seg-lung.nii.gz\",\n",
    "        \"seg_lesion\": subject_source_dir / f\"{subject_id}_seg-lesion.nii.gz\",\n",
    "        \"seg_lesion_refined\": subject_source_dir / f\"{subject_id}_seg-lesion-refined.nii.gz\",\n",
    "    }\n",
    "\n",
    "    # Check for core files required for the entire process\n",
    "    if not all(p.exists() for p in [path_map[\"ct\"], path_map[\"pet\"], path_map[\"seg_lung\"]]):\n",
    "        print(f\"Warning: Skipping {subject_id} due to missing CT, PET, or lung segmentation.\")\n",
    "        return\n",
    "\n",
    "    # 2. Read all existing images\n",
    "    images = {key: sitk.ReadImage(str(path)) for key, path in path_map.items() if path.exists()}\n",
    "    \n",
    "    # 3. Resample\n",
    "    target_spacing = config['preprocessing']['target_spacing']\n",
    "    template_image = calculate_resample_template(images[\"ct\"], images[\"pet\"], target_spacing)\n",
    "    \n",
    "    resampled_images = {}\n",
    "    for key, img in images.items():\n",
    "        interpolator = sitk.sitkNearestNeighbor if \"seg\" in key else sitk.sitkLinear\n",
    "        default_value = 0 if \"pet\" in key or \"seg\" in key else -1024\n",
    "        resampled_images[key] = resample_image(img, template_image, default_value, interpolator)\n",
    "\n",
    "    # 4. Crop\n",
    "    min_lung_size = config['preprocessing']['min_lung_size']\n",
    "    cleaned_lung_mask = remove_small_objects(resampled_images[\"seg_lung\"], min_size=min_lung_size)\n",
    "    \n",
    "    try:\n",
    "        bounding_box = get_bounding_box(cleaned_lung_mask)\n",
    "    except ValueError as e:\n",
    "        print(f\"Warning: Could not find bounding box for {subject_id}. {e}\")\n",
    "        return\n",
    "\n",
    "    cropped_images = {key: crop_to_bounding_box(img, bounding_box) for key, img in resampled_images.items()}\n",
    "\n",
    "    # 5. Save the final cropped images\n",
    "    subject_output_dir = output_dir / subject_id\n",
    "    subject_output_dir.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    for key, img in cropped_images.items():\n",
    "        output_filename = path_map[key].name\n",
    "        sitk.WriteImage(img, str(subject_output_dir / output_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "852e0888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1030 subjects to process.\n",
      "Source directory: /home/yaobo/Project/Lung-Cancer-Subtyping-Classification-V4.0/data/0_nifti\n",
      "Output directory: /home/yaobo/Project/Lung-Cancer-Subtyping-Classification-V4.0/data/1_preprocessed\n"
     ]
    }
   ],
   "source": [
    "# Define paths from config\n",
    "source_data_dir = project_root / config['paths']['data_root']\n",
    "preprocessed_data_dir = project_root / config['preprocessing']['output_dir']\n",
    "\n",
    "# Create the output directory\n",
    "preprocessed_data_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Get a list of all subject IDs from the source directory\n",
    "all_subject_ids = [d.name for d in source_data_dir.iterdir() if d.is_dir() and d.name.startswith('sub-')]\n",
    "\n",
    "print(f\"Found {len(all_subject_ids)} subjects to process.\")\n",
    "print(f\"Source directory: {source_data_dir}\")\n",
    "print(f\"Output directory: {preprocessed_data_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e80633b",
   "metadata": {},
   "source": [
    "## 3. Run Preprocessing Loop\n",
    "\n",
    "Iterate through all subjects and apply the `preprocess_subject` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c3e937",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preprocessing Subjects:  63%|██████▎   | 648/1030 [23:03<12:42,  2.00s/it, sub-AKHECKLJACEKALFRED20221031]                   "
     ]
    }
   ],
   "source": [
    "with tqdm(all_subject_ids, desc=\"Preprocessing Subjects\") as pbar:\n",
    "    for subject_id in pbar:\n",
    "        pbar.set_postfix_str(subject_id)\n",
    "        try:\n",
    "            preprocess_subject(\n",
    "                subject_id=subject_id,\n",
    "                source_dir=source_data_dir,\n",
    "                output_dir=preprocessed_data_dir,\n",
    "                config=config\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"FATAL ERROR processing {subject_id}: {e}\")\n",
    "\n",
    "print(\"\\nPreprocessing pipeline finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "totalseg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
